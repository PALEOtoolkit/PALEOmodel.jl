"""
    OutputWriters

Data structures and methods to hold and manage model output.
"""
module OutputWriters

import PALEOboxes as PB

import PALEOmodel

import DataFrames
import FileIO
import JLD2
import NCDatasets

import Infiltrator # Julia debugger


##################################
# AbstractOutputWriter interface
###################################

"""
    AbstractOutputWriter

Interface implemented by containers for PALEO model output.

Implementations should define methods for:

# Writing output
- [`initialize!`](@ref)
- [`add_record!`](@ref)

# Modifying output
- [`PB.add_field!`](@ref)

# Querying output
- [`PB.get_table`](@ref)
- [`PB.show_variables`](@ref)
- [`PB.has_variable`](@ref)

# Accessing output data
- [`PALEOmodel.get_array`](@ref)
- [`PB.get_field`](@ref)
- [`PB.get_mesh`](@ref)
- [`PB.get_data`](@ref)

"""
PALEOmodel.AbstractOutputWriter

"""
    initialize!(
        output::PALEOmodel.AbstractOutputWriter, model, modeldata, nrecords 
        [;coords_record=:tmodel] [coords_record_units="year"]
    )

Initialize from a PALEOboxes::Model, reserving memory for an assumed output dataset of `nrecords`.

The default for `coords_record` is `:tmodel`, for a sequence of records following the time evolution
of the model.
"""
function initialize!(
    output::PALEOmodel.AbstractOutputWriter, model::PB.Model, modeldata::PB.ModelData, nrecords
)
end

"""
    add_record!(output::PALEOmodel.AbstractOutputWriter, model, modeldata, rec_coord)

Add an output record for current state of `model` at record coordinate `rec_coord`.
The usual case (set by [`initialize!`](@ref)) is that the record coordinate is model time `tmodel`.
"""
function add_record!(output::PALEOmodel.AbstractOutputWriter, model, modeldata, rec_coord) end

"""
    add_field!(output::PALEOmodel.AbstractOutputWriter, fr::PALEOmodel.FieldRecord) 

Add [`PALEOmodel.FieldRecord`](@ref) `fr` to `output`, with Domain and name defined by `fr.attributes[:var_domain]` and
`fr.attributes[:var_name]`.
"""
function PB.add_field!(output::PALEOmodel.AbstractOutputWriter, fr::PALEOmodel.FieldRecord) end

"""
    get_table(output::PALEOmodel.AbstractOutputWriter, domainname::AbstractString) -> Table
    get_table(output::PALEOmodel.AbstractOutputWriter, varnames::Vector{<:AbstractString}) -> Table

Return a `DataFrame` with raw model `output` data for Domain `domainname`, or for Variables `varnames`
"""
function PB.get_table(output::PALEOmodel.AbstractOutputWriter, domainname::AbstractString) end

"""
    has_variable(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString)  -> Bool

True if model `output` contains Variable `varname`.
"""
function PB.has_variable(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString) end


"""
    show_variables(output::PALEOmodel.AbstractOutputWriter; kwargs...) -> Table
    show_variables(output::PALEOmodel.AbstractOutputWriter, domainname::AbstractString; kwargs...) -> Table

# Keywords:
- `attributes=[:units, :vfunction, :space, :field_data, :description]`: Variable attributes to include
- `filter = attrb->true`: function to filter by Variable attributes.
  Example: `filter=attrb->attrb[:vfunction]!=PB.VF_Undefined` to show state Variables and derivatives.

# Examples:
    julia> vscodedisplay(PB.show_variables(run.output))  # show all output Variables in VS code table viewer
    julia> vscodedisplay(PB.show_variables(run.output, ["atm.pCO2PAL", "fluxOceanBurial.flux_P_total"]))  # show subset of output Variables in VS code table viewer
"""
function PB.show_variables(output::PALEOmodel.AbstractOutputWriter) end

"""
    get_array(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString [, allselectargs::NamedTuple] [; coords::AbstractVector]) -> FieldArray
    get_array(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString; allselectargs...) -> FieldArray

Return a [`PALEOmodel.FieldArray`](@ref) containing data values and any attached coordinates, for the 
[`PALEOmodel.FieldRecord`](@ref) for `varname`, and records and spatial region defined by `selectargs`
    
If `coords` is not supplied, equivalent to `PALEOmodel.get_array(PB.get_field(output, varname), allselectargs)`.

Optional argument `coords` can be used to supply plot coordinates from Variable in output, to replace any default coordinates.
Format is a Vector of Pairs of "coord_name"=>("var_name1", "var_name2", ...)

Example: to replace a 1D column default pressure coordinate with a z coordinate:
 
    coords=["z"=>("atm.zmid", "atm.zlower", "atm.zupper")]

NB: the coordinates will be generated by applying `selectargs`,
so the supplied coordinate Variables must have the same dimensionality as `vars`.
"""
function PALEOmodel.get_array(
    output::PALEOmodel.AbstractOutputWriter, varname::AbstractString;
    coords=nothing,
    allselectargs...
)  
    isempty(allselectargs) ||
        Base.depwarn(
            "allselectargs... will be deprecated in a future release.  Please use allselectargs::NamedTuple instead",
            :get_array,
        )
    return PALEOmodel.get_array(output, varname, NamedTuple(allselectargs); coords=coords)
end

function PALEOmodel.get_array(
    output::PALEOmodel.AbstractOutputWriter, varname::AbstractString, allselectargs::NamedTuple; # allselectargs::NamedTuple=NamedTuple() creates a method ambiguity with deprecated form above
    coords=nothing,
)
    fr = PB.get_field(output, varname)   

    if isnothing(coords)
        coords_records=nothing
    else
        PALEOmodel.check_coords_argument(coords) ||
            error("argument coords should be a Vector of Pairs of \"coord_name\"=>(\"var_name1\", \"var_name2\", ...), eg: [\"z\"=>(\"atm.zmid\", \"atm.zlower\", \"atm.zupper\"), ...]")

        coords_records = [
            coord_name => Tuple(PB.get_field(output, cvn) for cvn in coord_varnames) 
            for (coord_name, coord_varnames) in coords
        ]
    end        

    return PALEOmodel.get_array(fr, allselectargs; coords=coords_records)
end

"""
    get_field(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString) -> FieldRecord

Return the [`PALEOmodel.FieldRecord`](@ref) for `varname`.
"""
function PB.get_field(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString) end

"""
    get_data(output::PALEOmodel.AbstractOutputWriter, varname; records=nothing) -> values

Get Variable `varname` raw data array, optionally restricting to `records`
"""
function PB.get_data(output::PALEOmodel.AbstractOutputWriter, varname::AbstractString; records=nothing) end

"""
    get_mesh(output::PALEOmodel.AbstractOutputWriter, domainname::AbstractString) -> grid::Union{AbstractMesh, Nothing}

Return `grid` for `output` Domain `domainname`.
"""
function PB.get_mesh(output::PALEOmodel.AbstractOutputWriter, domainname::AbstractString) end


##########################
# OutputMemoryDomain
###########################

"""
    OutputMemoryDomain

In-memory model output, for one model Domain.

Includes an additional `coords_record` (usually `:tmodel`, when storing output vs time).

# Implementation
`data::DataFrame` contains columns of same type as `FieldRecord.records` for each Variable.
"""
mutable struct OutputMemoryDomain
    "Domain name"
    name::String
    "Model output for this Domain"
    data::DataFrames.DataFrame
    "record coordinate"
    coords_record::Symbol
    "Domain data_dims"
    data_dims::Vector{PB.NamedDimension}
    "Variable metadata (attributes) (metadata[varname] -> attributes::Dict{Symbol, Any})"
    metadata::Dict{String, Dict{Symbol, Any}}
    "Domain Grid (if any)"
    grid::Union{PB.AbstractMesh, Nothing}

    # internal use only: all Variables in sorted order
    _all_vars::Vector{PB.VariableDomain}
    # current last record in preallocated data::DataFrame (may be less than length(data))
    _nrecs
end

Base.length(output::OutputMemoryDomain) = output._nrecs

"create from a PALEOboxes::Domain"
function OutputMemoryDomain(
    dom::PB.Domain, modeldata::PB.ModelData, nrecords::Integer; 
    coords_record::Symbol=:tmodel, coords_record_units::AbstractString="year"
)
  
    odom =  OutputMemoryDomain(
        dom.name,
        DataFrames.DataFrame(),        
        coords_record,
        deepcopy(dom.data_dims),
        Dict{String, Dict{Symbol, Any}}(),
        deepcopy(dom.grid),
        PB.VariableDomain[],
        0,       
    )

    # create list of variables sorted by host dependent type, then by name
    odom._all_vars = vcat(
        sort(
            PB.get_variables(
                dom, v->PB.get_attribute(v, :vfunction, PB.VF_Undefined) in (PB.VF_StateExplicit, PB.VF_Total, PB.VF_Constraint)
            ), 
            by=var->var.name
        ),
        sort(
            PB.get_variables(dom, v->PB.get_attribute(v, :vfunction, PB.VF_Undefined) in (PB.VF_Deriv,)),
            by=var->var.name
        ),
        sort(
            PB.get_variables(dom, v->PB.get_attribute(v, :vfunction, PB.VF_Undefined) in (PB.VF_State, PB.VF_StateTotal)),
            by=var->var.name
        ),
        sort(
            PB.get_variables(
                dom, v-> !(PB.get_attribute(v, :vfunction, PB.VF_Undefined) in (PB.VF_StateExplicit, PB.VF_Total, PB.VF_StateTotal, PB.VF_Constraint, PB.VF_Deriv, PB.VF_State))),
            by=var->var.name
        ),
    )
    
    # add empty (ie undefined) columns to dataframe

    # add record coordinate column
    DataFrames.insertcols!(
        odom.data, 
        DataFrames.ncol(odom.data)+1, 
        coords_record => Vector{Float64}(undef, nrecords)
    )   
    odom.metadata[String(coords_record)] = Dict(
        :var_name=>String(coords_record), :domain_name=>dom.name,
        :vfunction=>PB.VF_Undefined, :description=>"output record coordinate",
        :field_data=>PB.ScalarData, :space=>PB.ScalarSpace, :data_dims=>(), :units=>coords_record_units,
    )

    # add variables
    for var in odom._all_vars
        # records storage type is that of FieldRecord.records
        field = PB.get_field(var, modeldata)
        if PALEOmodel.field_single_element(field)
            # if Field contains single elements, store as a Vector of elements
            records = Vector{eltype(field.values)}(undef, nrecords)
        else
            # if Field contains something else, store as a Vector of those things
            records = Vector{typeof(field.values)}(undef, nrecords)
        end
       
        DataFrames.insertcols!(
            odom.data, 
            DataFrames.ncol(odom.data)+1, 
            Symbol(var.name) => records
        )            

        attrbs = deepcopy(var.attributes)
        attrbs[:var_name] = var.name
        attrbs[:domain_name] = dom.name
        odom.metadata[var.name] = attrbs
    end

    return odom
end

"create from a DataFrames DataFrame containing scalar data"
function OutputMemoryDomain(
    name::AbstractString, data::DataFrames.DataFrame;
    coords_record::Symbol=:tmodel, coords_record_units::AbstractString="year",
    metadata::Dict{String, Dict{Symbol, Any}}=Dict(String(coords_record)=>Dict{Symbol, Any}(:units=>coords_record_units)),    
)
    # create minimal metadata for scalar Variables
    for vname in DataFrames.names(data)
        vmeta = get!(metadata, vname, Dict{Symbol, Any}())
        vmeta[:var_name] = vname
        vmeta[:domain_name] = name
        vmeta[:field_data] = PB.ScalarData
        vmeta[:space] = PB.ScalarSpace
        vmeta[:data_dims] = ()
    end

    return OutputMemoryDomain(
        name,
        data,
        coords_record,
        [],
        metadata,
        nothing,
        [],
        DataFrames.nrow(data)
    )

end

"""
    OutputMemoryDomain(name::AbstractString, coords_record::PALEOmodel.FieldRecord)

Create from a `coords_record` (eg defining `tmodel`). Add additional Fields with
`add_field!`.
"""
function OutputMemoryDomain(
    name::AbstractString, coords_record::PALEOmodel.FieldRecord;
    data_dims::Vector{PB.NamedDimension} = Vector{PB.NamedDimension}(),
    grid = nothing,
)
    data = DataFrames.DataFrame()

    haskey(coords_record.attributes, :var_name) ||
        throw(ArgumentError("FieldRecord has no :var_name attribute"))
    varname = coords_record.attributes[:var_name]
   
    DataFrames.insertcols!(data, Symbol(varname)=>coords_record.records)
    metadata = Dict(varname=>deepcopy(coords_record.attributes))
    # update domain name 
    metadata[varname][:domain_name] = name

    return OutputMemoryDomain(
        name,
        data,
        Symbol(varname),
        data_dims,
        metadata,
        grid,
        [],
        DataFrames.nrow(data)
    )

end


function add_record!(odom::OutputMemoryDomain, modeldata, rec_coord)
        
    odom._nrecs +=1       
    df = odom.data

    df[!, odom.coords_record][odom._nrecs] = rec_coord

    for var in odom._all_vars
        field = PB.get_field(var, modeldata)
        values = PB.get_values_output(field)
        
        if PALEOmodel.field_single_element(field)
            df[!, Symbol(var.name)][odom._nrecs] = values[]
        else
            # copy array(s) data                           
            df[!, Symbol(var.name)][odom._nrecs] = copy(values)
        end
    end

    return nothing
end

function PB.add_field!(odom::OutputMemoryDomain, fr::PALEOmodel.FieldRecord)
    
    length(fr) == length(odom) ||
        throw(ArgumentError("FieldRecord length $(length(fr)) != OutputMemoryDomain length $(length(odom))"))

    haskey(fr.attributes, :var_name) ||
        throw(ArgumentError("FieldRecord has no :var_name attribute"))
    varname = fr.attributes[:var_name]
    !(Symbol(varname) in names(odom.data)) ||
        throw(ArgumentError("Variable $varname already exists"))

    DataFrames.insertcols!(odom.data, Symbol(varname)=>fr.records)
    odom.metadata[varname] = deepcopy(fr.attributes)
    # update domain name 
    odom.metadata[varname][:domain_name] = odom.name

    return nothing
end

function PB.get_field(odom::OutputMemoryDomain, varname)

    df = odom.data
    varname in DataFrames.names(df) || 
        error("Variable $varname not found in output (no column '$varname' in Dataframe output.domains[\"$(odom.name)\"].data)")

    use_all_records = DataFrames.nrow(df) == odom._nrecs
    # vdata = df[!, Symbol(varname)]
    vdata = use_all_records ? df[!, Symbol(varname)] : df[1:odom._nrecs, Symbol(varname)]

    attributes = get(odom.metadata, varname, nothing)

    !isnothing(attributes) ||
        @error "$(odom.name).$varname has no attributes"

    grid = odom.grid

    data_dims = []
    for dimname in attributes[:data_dims]
        idx = findfirst(d -> d.name==dimname, odom.data_dims)
        !isnothing(idx) ||
            error("Domain $(odom.name) has no dimension='$dimname' (available dimensions: $(odom.data_dims)")
        push!(data_dims, odom.data_dims[idx])
    end

    field_data = attributes[:field_data]
    space = attributes[:space]

    fr = PALEOmodel.wrap_fieldrecord(
        vdata, field_data, Tuple(data_dims), missing, space, grid, attributes,
        coords_record=[
            PB.FixedCoord(
                String(odom.coords_record),
                # df[!, odom.coords_record],
                use_all_records ? df[!, odom.coords_record] : df[1:odom._nrecs, odom.coords_record],
                odom.metadata[String(odom.coords_record)]
            ),
        ]
    )

    return fr
end


function PB.show_variables(
    odom::OutputMemoryDomain; 
    attributes=[:units, :vfunction, :space, :field_data, :description],
    filter = attrb->true, 
)
    shownames = []
    for vn in names(odom.data)
        if filter(odom.metadata[vn])
            push!(shownames, vn)
        end
    end
    sort!(shownames)
    
    df = DataFrames.DataFrame()
    df.name = shownames
    for att in attributes
        DataFrames.insertcols!(df, att=>[get(odom.metadata[vn], att, missing) for vn in shownames])
    end   

    return df
end

########################################
# OutputMemory
##########################################

const UserDataTypes = Union{Float64, Int64, String, Vector{Float64}, Vector{Int64}, Vector{String}}

"""
    OutputMemory(; user_data=Dict{String, UserDataTypes}())

In-memory container for model output, organized by model Domains.

Implements the [`PALEOmodel.AbstractOutputWriter`](@ref) interface, with additional methods
[`save_netcdf`](@ref) and [`load_netcdf!`](@ref) to save and load data.

# Implementation
- Field `domains::Dict{String, OutputMemoryDomain}` contains per-Domain model output.
- Field `user_data::Dict{String, UserDataTypes}` contains optional user data
  NB:
  - available types are restricted to those that are compatible with NetCDF attribute types,
    ie Float64, Int64, String, Vector{Float64}, Vector{Int64}, Vector{String}
  - Vectors with a single element are read back from netcdf as scalars,
    see https://alexander-barth.github.io/NCDatasets.jl/dev/issues/#Corner-cases
"""
struct OutputMemory <: PALEOmodel.AbstractOutputWriter
    domains::Dict{String, OutputMemoryDomain}
    user_data::Dict{String, UserDataTypes}
end


const default_user_data=Dict{String, UserDataTypes}(
    "title"=>"PALEO (exo)Earth system model output",
    "source"=>"PALEOmodel https://github.com/PALEOtoolkit/PALEOmodel.jl",
)

function OutputMemory(; user_data=default_user_data)
    return OutputMemory(Dict{String, OutputMemoryDomain}(), user_data)
end

"create from collection of OutputMemoryDomain"
function OutputMemory(output_memory_domains::Union{Vector, Tuple}; user_data=default_user_data)
    om = OutputMemory(Dict(om.name => om for om in output_memory_domains), user_data)
    return om
end

function Base.length(output::OutputMemory)
    lengths = unique([length(omd) for (k, omd) in output.domains])
    length(lengths) == 1 ||
        error("output $output has Domains of different lengths")

    return lengths[]
end


function PB.get_table(output::OutputMemory, domainname::AbstractString)
    haskey(output.domains, domainname) ||
        throw(ArgumentError("no Domain $domainname"))

    return output.domains[domainname].data
end

function PB.get_table(output::OutputMemory, varnames::Vector{<:AbstractString})
    df = DataFrames.DataFrame()

    for varname in varnames
        if contains(varname, ".")
            vdom, vname = split(varname, ".")
            if haskey(output.domains, vdom)
                dfdom = output.domains[vdom].data
                if vname in names(dfdom)
                    vardata = dfdom[:, Symbol(vname)]
                    df = DataFrames.insertcols!(df, varname=>vardata)
                else
                    @warn "no Variable found for $varname"
                end
            else
                @warn "no Domain found for $varname"
            end
        else
            @warn "Variable $varname is not of form <Domain>.<Name>"
        end
    end
    return df
end

function PB.get_mesh(output::OutputMemory, domainname::AbstractString)
    haskey(output.domains, domainname) ||
        throw(ArgumentError("no Domain $domainname"))

    return output.domains[domainname].grid
end

function PB.show_variables(
    output::OutputMemory, domainname::AbstractString; kwargs...
)
    haskey(output.domains, domainname) ||
        throw(ArgumentError("no Domain $domainname"))

    return PB.show_variables(output.domains[domainname]; kwargs...)
end

function PB.show_variables(output::OutputMemory; kwargs...)
    df = DataFrames.DataFrame()
    for (domname, odom) in output.domains
        dfdom = PB.show_variables(odom; kwargs...)
        # prepend domain name
        DataFrames.insertcols!(dfdom, 1, :domain=>fill(domname, size(dfdom,1)))
        # append to df
        df = vcat(df, dfdom)
    end
    DataFrames.sort!(df, [:domain, :name])
    return df
end


"""
    save_jld2(output::OutputMemory, filename)

Deprecated - use [`save_netcdf`](@ref)

Save to `filename` in JLD2 format (NB: filename must either have no extension or have extension `.jld2`)
"""
function save_jld2(output::OutputMemory, filename)

    @warn """Files created by save_jld2 will not be readable with future versions of PALEO
             Please use save_netcdf instead"""

    filename = _check_filename_ext(filename, ".jld2")

    # create a temporary copy to omit _all_vars
    output_novars = copy(output.domains)
    for (k, omd) in output_novars
        output_novars[k] = OutputMemoryDomain(
            omd.name,
            omd.data,
            omd.coords_record,
            omd.data_dims,
            omd.metadata,
            omd.grid,
            [],  # omit _allvars
            omd._nrecs,
        )        
    end

    @info "saving to $filename ..."
    FileIO.save(filename, output_novars)
    @info "done"

    return nothing
end

"""
    load_jld2!(output::OutputMemory, filename)

Load from `filename` in JLD2 format, replacing any existing content in `output`.
(NB: filename must either have no extension or have extension `.jld2`).

# Example
```julia
julia> output = PALEOmodel.OutputWriters.load_jld2!(PALEOmodel.OutputWriters.OutputMemory(), "savedoutput.jld2")
```
"""
function load_jld2!(output::OutputMemory, filename)

    filename = _check_filename_ext(filename, ".jld2")

    @info "loading from $filename ..."

    jld2data = FileIO.load(filename) # returns Dict

    empty!(output.domains)
    for (domainname, odom) in jld2data
        output.domains[domainname] = odom
    end

    return output
end



"append output2 to the end of output1"
function Base.append!(output1::OutputMemory, output2::OutputMemory)
    for domname in keys(output1.domains)
        o1dom, o2dom = output1.domains[domname], output2.domains[domaname]
        append!(o1dom.data, o2dom.data)
        o1dom.nrecs += o2dom.nrecs
    end
  
    return output1
end


function initialize!(
    output::OutputMemory, model::PB.Model, modeldata::PB.ModelData, nrecords;
    rec_coord::Symbol=:tmodel, # deprecated
    coords_record::Symbol=rec_coord, coords_record_units::AbstractString="yr",    
)

    # Create Dict of DataFrames with output
    empty!(output.domains)
    for dom in model.domains
        output.domains[dom.name] = OutputMemoryDomain(
            dom, modeldata, nrecords,
            coords_record=coords_record,
            coords_record_units=coords_record_units,
        )
    end
  
    return nothing
end


function add_record!(output::OutputMemory, model, modeldata, rec_coord)

    for dom in model.domains
        odom = output.domains[dom.name]
        add_record!(odom, modeldata, rec_coord)
    end
end

function PB.has_variable(output::OutputMemory, varname::AbstractString)

    domainname, varname = domain_variable_name(varname)

    return (
        haskey(output.domains, domainname) 
        && varname in DataFrames.names(output.domains[domainname].data)
    )
end

function PB.get_field(output::OutputMemory, varname::AbstractString)
  
    domainname, varname = domain_variable_name(varname)
    
    haskey(output.domains, domainname) || 
        error("Variable $varname not found in output: domain $(domainname) not present")

    odom = output.domains[domainname]

    return PB.get_field(odom, varname)
end


function PB.add_field!(output::OutputMemory, fr::PALEOmodel.FieldRecord)
    domainname = PB.get(fr.attributes, :var_domain, nothing)

    haskey(output.domains) ||
        throw(ArgumentError("no Domain $domainname in output $output"))
    return PB.add_field!(output.domains[domainname], fr)
end

function PB.get_data(output::OutputMemory, varnamefull::AbstractString; records=nothing)

    domainname, varname = domain_variable_name(varnamefull, defaultdomainname=nothing)
    
    haskey(output.domains, domainname) || 
        error("Variable $varnamefull not found in output: domain $(domainname) not present")

    odom = output.domains[domainname]
    df = odom.data
    varname in DataFrames.names(df) || 
        error("Variable $varname not found in output (no column '$varname' in Dataframe output.domains[\"$domainname\"].data)")
    
    if isnothing(records)
        output = df[!, Symbol(varname)]
    else
        output = df[records, Symbol(varname)]
        # bodge - fix scalar data
        if isa(records, Integer) && !isa(output, AbstractVector)
            output =[output]
        end
    end

    return output
end    


###########################
# Pretty printing
############################

"compact form"
function Base.show(io::IO, odom::OutputMemoryDomain)
    print(io, 
        "OutputMemoryDomain(name=", odom.name,
        ", data_dims=", odom.data_dims, 
        ", length=", length(odom), 
    ")")
end

"compact form"
function Base.show(io::IO, output::OutputMemory)
    print(io, "OutputMemory(domains=", keys(output.domains), ", user_data=", output.user_data, ")")
end



############################
# Utility functions
############################

function domain_variable_name(varnamefull; defaultdomainname=nothing)
    varsplit = split(varnamefull, '.')
    if length(varsplit) == 1
        !isnothing(defaultdomainname) ||
            error("domain_variable_name: \"$varnamefull\" is not of form <domainname>.<varname>")
        domainname = defaultdomainname
        varname = varnamefull       
    elseif length(varsplit) == 2
        domainname = varsplit[1]
        varname = varsplit[2]
    else
        error("domain_variable_name: invalid 'varnamefull' = \"$varnamefull\" is not of form <domainname>.<varname>")
    end

    return domainname, varname
end

###############################################
# netCDF i/o
###############################################


"""
    save_netcdf(output::OutputMemory, filename; kwargs...)

Save to `filename` in netcdf4 format (NB: filename must either have no extension or have extension `.nc`)

# Notes on structure of netcdf output
- Each PALEO Domain is written to a netcdf4 group. These can be read into a Python xarray using the `group=<domainname>` argument to `open_dataset`.
- Isotope-valued variables (`field_data = PB.IsotopeLinear`) are written with an extra `isotopelinear` netCDF dimension, containing the variable `total` and `delta`.
- Any '/' characters in PALEO variables are substited for '%' in the netcdf name.

# Keyword arguments
- `check_ext::Bool = true`: check that filename ends in ".nc"
- `add_coordinates::Bool = false`: true to attempt to add CF convention coords to variables (experimental, doesn't look that useful)
"""
function save_netcdf(
    output::OutputMemory, filename;
    check_ext::Bool=true,
    add_coordinates::Bool=false,
)
    if check_ext
        filename = _check_filename_ext(filename, ".nc")
    end

    # Fails with variables with missing values eg that are  Union{Missing, Float64}
    # appears to be a NCDatasets.jl limitation (at least in v0.12.17) - the logic to map these to netcdf is 
    # combined with that to write the data, and the alternate form with just the type fails
    # TODO may not work with NCDatasets v0.13 and later due to variable indexing changes ?
    define_all_first = false 
    # define_all_first = true

    @info "saving to $filename ..."

    NCDatasets.NCDataset(filename, "c") do nc_dataset
        nc_dataset.attrib["PALEO_netcdf_version"] = "0.1.0"
        nc_dataset.attrib["PALEO_domains"] =  join([k for (k, v) in output.domains], " ")

        for (k, v) in output.user_data
            if k in ("PALEO_netcdf_version", "PALEO_domains")
                @warn "ignoring reserved user_data key $k"
                continue
            end
            nc_dataset.attrib[k] = v
        end

        for (domname, dom) in output.domains

            dsg = NCDatasets.defGroup(nc_dataset, dom.name; attrib=[])
            coords_record = String(dom.coords_record) # record dimension (eg tmodel)
            dsg.attrib["coords_record"] =  coords_record
            NCDatasets.defDim(dsg, coords_record, dom._nrecs)

            spatial_dimnames, spatial_unpackfn = grid_to_netcdf!(dsg, dom.grid)

            # data_dims
            # TODO these are NamedDimension with attached FixedCoord, where
            # the FixedCoord may not be present as a variable in the data,
            # and may also not have the correct name or even a unique name !
            # As a workaround, we generate a unique name from dim_name * coord_name, and add the Variable
            data_dim_names = String[d.name for d in dom.data_dims]
            dsg.attrib["data_dims"] = data_dim_names
            for data_dim in dom.data_dims
                NCDatasets.defDim(dsg, data_dim.name, data_dim.size)
                gen_unique_coord_names = String[data_dim.name*"_"*co.name for co in data_dim.coords]
                dsg.attrib[data_dim.name*"_coords"] = gen_unique_coord_names
                for (co, coname) in zip(data_dim.coords, gen_unique_coord_names)
                    # add variable
                    v = NCDatasets.defVar(dsg, coname, co.values, (data_dim.name,))
                    attributes_to_netcdf!(v, co.attributes)
                end
            end        

            colnames = sort(names(dom.data))
            added_isotopelinear_dims = false
            nc_all_vdata = []
            for vname in colnames
                haskey(dom.metadata, vname) || error("no metadata for Variable $(dom.name).$vname")

                attributes = dom.metadata[vname]
                # see get_field method above
                data_dims = attributes[:data_dims]            
                field_data = attributes[:field_data]
                space = attributes[:space]

                if field_data == PB.IsotopeLinear && !added_isotopelinear_dims
                    NCDatasets.defDim(dsg, "isotopelinear", 2)
                    v = NCDatasets.defVar(dsg, "isotopelinear", ["total", "delta"], ("isotopelinear",))
                    v.attrib["comment"] = "components of an isotope variable"
                    added_isotopelinear_dims = true
                end

                vdata = dom.data[1:dom._nrecs, vname] 
                @debug "writing Variable $(dom.name).$vname dframe eltype $(eltype(vdata)) space $space"

                nc_v, nc_vdata = variable_to_netcdf!(
                    dsg,
                    coords_record,
                    vname, 
                    vdata, 
                    field_data,
                    spatial_dimnames,
                    spatial_unpackfn,
                    data_dims, 
                    space, 
                    dom.grid, 
                    attributes;
                    add_coordinates,
                    define_only=define_all_first,  # just define the variable, don't write the data
                )
                
                if define_all_first
                    # keep netcdf variable and modified data to write in separate loop
                    push!(nc_all_vdata, (nc_v, nc_vdata))
                end
            end

            # write data (only used if define_all_first==true)
            for (nc_v, nc_vdata) in nc_all_vdata
                # TODO may not work with NCDatasets v0.13 and later ?
                nc_v[:] = nc_vdata
            end
        end
    end
   
    @info "done"

    return nothing
end


"""
    load_netcdf!(output::OutputMemory, filename)

Load from `filename` in netCDF format, replacing any existing content in `output`.
(NB: filename must either have no extension or have extension `.nc`).

# Example
```julia
julia> output = PALEOmodel.OutputWriters.load_netcdf!(PALEOmodel.OutputWriters.OutputMemory(), "savedoutput.nc")
```
"""
function load_netcdf!(output::OutputMemory, filename; check_ext=true)

    if check_ext
        filename = _check_filename_ext(filename, ".nc")
    end

    @info "loading from $filename ..."

    NCDatasets.NCDataset(filename, "r") do nc_dataset
        empty!(output.domains)

        paleo_netcdf_version = get(nc_dataset.attrib, "PALEO_netcdf_version", missing)
        !ismissing(paleo_netcdf_version) || error("not a PALEO netcdf output file ? (key PALEO_netcdf_version not present)")
        paleo_netcdf_version == "0.1.0" || error("unsupported PALEO_netcdf_version $paleo_netcdf_version")

        for (k, v) in nc_dataset.attrib
            if k in ("PALEO_netcdf_version", "PALEO_domains")
                continue
            end
            # workaround for https://github.com/Alexander-Barth/NCDatasets.jl/issues/258
            if v isa Int32
                v = Int64(v)
            elseif v isa Vector{Int32}
                v = Int64.(v)
            end
            output.user_data[k] = v
        end

        for (domainname, dsg) in nc_dataset.group
            coords_record = dsg.attrib["coords_record"]
            nrecs = dsg.dim[coords_record]
            data = DataFrames.DataFrame()
            metadata = Dict{String, Dict{Symbol, Any}}()

            # reading out variables is slow, so do this once
            dsgvars = Dict(varname=>var for (varname, var) in dsg)

            grid, spatial_packfn = netcdf_to_grid(dsg, dsgvars)

            data_dim_names = ncattrib_as_vector(dsg, "data_dims")
            data_dim_sizes = [dsg.dim[ddn] for ddn in data_dim_names]
            data_dims = PB.NamedDimension[]
            for (ddn, dds) in zip(data_dim_names, data_dim_sizes)
                dd_coords = PB.FixedCoord[]
                for dd_coord_name in ncattrib_as_vector(dsg, ddn*"_coords")
                    var = dsgvars[dd_coord_name]
                    attributes = netcdf_to_attributes(var)
                    !(coords_record in NCDatasets.dimnames(var)) || error("data_dim coord variable $dd_coord_name is not constant! (has a $coords_record dimension)")
                    push!(dd_coords, PB.FixedCoord(dd_coord_name, Array(var), attributes))
                end
                push!(data_dims, PB.NamedDimension(ddn, dds, dd_coords))
            end

            for (vnamenetcdf, var) in dsgvars
                if haskey(var.attrib, "var_name") # a PALEO variable, not eg a grid variable                    
                    attributes = netcdf_to_attributes(var)
                    vname = netcdf_to_name(vnamenetcdf, attributes)
                    metadata[vname] = attributes
                    vdata = netcdf_to_variable(
                        var,
                        coords_record, 
                        attributes,
                        grid,
                        spatial_packfn,
                        nrecs,
                    )
                    data[!, vname] = vdata
                end
            end

            output.domains[domainname] = OutputMemoryDomain(
                domainname,
                data,
                Symbol(coords_record),
                data_dims,
                metadata,
                grid,
                [],  # omit _allvars
                nrecs,
            )

        end
    end

    return output
end


# write a variable to netcdf. cf get_field, wrap_fieldrecord
function variable_to_netcdf!(
    ds,
    coords_record::AbstractString,
    vname::AbstractString, 
    vdata::Vector, 
    field_data::Type{<:PB.AbstractData},
    grid_spatial_dims::NTuple{NS, String},
    spatial_unpackfn,
    data_dims::NTuple{ND, String}, 
    space::Type{S}, 
    grid::Union{Nothing, PB.AbstractMesh}, 
    attributes;
    add_coordinates=false,
    define_only=true,
) where {NS, ND, S <: PB.AbstractSpace}

    if space === PB.ScalarSpace
        spatial_dims = ()
        unpackfn = identity
    else
        spatial_dims = grid_spatial_dims
        unpackfn = spatial_unpackfn
    end
    coordinates = [spatial_dims...]
   
    vname = name_to_netcdf(vname, attributes)

    if variable_is_constant(vname, vdata, attributes)
        v_records_dim = ()
        vdata = unpackfn(first(vdata))
    else
        v_records_dim = (coords_record,)
        if !PALEOmodel.field_single_element(field_data, ND, space, typeof(grid))
            # concatenate to array
            vdata =  vectors_to_array(vdata, unpackfn)
        end
        push!(coordinates, coords_record)
    end

    field_data_dims = field_data_netcdf_dimensions(field_data)
    vdata = field_data_to_netcdf(field_data, vdata)

    # if define_only = true, only define the variable, don't actually write the data
    # (allows optimisation as netcdf is slow to swap between 'define' and 'data' mode)
    # TODO fails if vdata contains missing (so eltype is eg Union{Missing, Float64}) at least with NCDatsets v0.12.17
    # https://github.com/Alexander-Barth/NCDatasets.jl/issues/223
    vdt = define_only ? eltype(vdata) : vdata
    v = NCDatasets.defVar(ds, vname, vdt, (field_data_dims..., spatial_dims..., data_dims..., v_records_dim...))
   
    attributes_to_netcdf!(v, attributes)
    if add_coordinates
        v.attrib["coordinates"] = join(coordinates, " ") # TODO CF convention for coordinates ?
    end
   
    return (v, vdata)
end

# read a variable from netcdf
function netcdf_to_variable(
    var,
    coords_record::AbstractString,
    attributes,
    grid,
    spatial_packfn,
    nrecs,
)

    field_data = attributes[:field_data]
    space = attributes[:space]
    data_dims = attributes[:data_dims]

    vdata = Array(var) # convert to Julia Array

    vdata = netcdf_to_field_data(vdata, field_data)
    
    packfn = space == PB.ScalarSpace ? identity : spatial_packfn

    if coords_record in NCDatasets.dimnames(var)
        if !PALEOmodel.field_single_element(field_data, length(data_dims), space, typeof(grid))
            vdata =  array_to_vectors(vdata, packfn)
        end
    else
        # OutputMemory has no concept of a constant variable, so replicate
        vdata = fill(packfn(vdata), nrecs) # scalar -> Vector, Array/Vector -> Vector of Arrays/Vectors
    end

    return vdata
end

# ScalarData no additional dimensions
field_data_netcdf_dimensions(field_data::Type{PB.ScalarData}) = ()
field_data_netcdf_dimensions(field_data::Type{PB.ArrayScalarData}) = ()
field_data_to_netcdf(field_data::Type, x) = x # fallback for ScalarData, ArrayScalarData

# serialize IsotopeLinear as (total, delta), NB: internal representation is (total, total*delta)
field_data_netcdf_dimensions(field_data::Type{PB.IsotopeLinear}) = ("isotopelinear",)
field_data_to_netcdf(field_data::Type{PB.IsotopeLinear}, x) = (x.v, x.v_delta)
field_data_to_netcdf(field_data::Type{PB.IsotopeLinear}, ::Missing) = (missing, missing)
function field_data_to_netcdf(field_data::Type{PB.IsotopeLinear}, x::Array{T}) where {T}

    # strip Missing, find out datatype, replace Missing
    isotopelinear_datatype(x::Type{PB.IsotopeLinear{T, T}}) where {T} = T
    OutEltype = Union{Missing, isotopelinear_datatype(nonmissingtype(T))}

    # add extra first dimension
    xout = Array{OutEltype}(undef, (2, size(x)...))
    for i in CartesianIndices(x)
        xout[:, i] .= field_data_to_netcdf(field_data, x[i])
    end
    return xout
end

netcdf_to_field_data(x, field_data::Type{<:PB.AbstractData}) = x # fallback

# julia> PALEOmodel.OutputWriters.netcdf_to_field_data([1.0, 2.0], PB.IsotopeLinear)
# (v=1.0, v_moldelta=2.0, ‰=2.0)
#
# julia> x = [1.0 3.0; 2.0 4.0]
# julia> xout = PALEOmodel.OutputWriters.netcdf_to_field_data(x, PB.IsotopeLinear)
# 2-element Vector{PALEOboxes.IsotopeLinear{Float64, Float64}}:
#  (v=1.0, v_moldelta=2.0, ‰=2.0)
#  (v=3.0, v_moldelta=12.0, ‰=4.0)
function netcdf_to_field_data(x, field_data::Type{PB.IsotopeLinear})
    # first dimension is two components of IsotopeLinear
    first(size(x)) == 2 || error("netcdf_to_field_data IsotopeLinear has wrong first dimension (should be 2)")
    if length(size(x)) == 1
        # scalar
        xout = PB.IsotopeLinear(x[1], x[1]*x[2])
    else
        sz = size(x)[2:end] # strip first dimension
        xout = Array{PB.IsotopeLinear{eltype(x), eltype(x)}}(undef, sz...)
        for i in CartesianIndices(xout)
            xout[i] = PB.IsotopeLinear(x[1, i], x[1, i]*x[2, i])
        end
    end

    return xout
end

# TODO PALEO has no real concept of time-independent variables
#  time-independent variables are indicated by setting data_type attribute,
# but this is also used for other purposes
# This uses data_type to guess if a variable is constant, and then checks the values
function variable_is_constant(vname::AbstractString, vdata::Vector, attributes)

    is_constant = false
    # PALEO indicates time-independent variables by setting data_type attribute    
    if get(attributes, :datatype, nothing) == Float64
        data_identical = false
        for v in vdata
            if v == first(vdata) || (all(isnan, v) && all(isnan, first(vdata)))
                data_identical = true
            end
        end
        if data_identical
            is_constant = true
        else
            @warn "variable $vname has :data_type Float64 but data is not constant !"
        end
    end

    return is_constant
end


"""
    vectors_to_array(vecvec::Vector{<:AbstractArray}, unpackfn) -> array::Array

Convert vector-of-vectors to Array,
with extra last dimension = length of vecvec

# Examples

    julia> PALEOmodel.OutputWriters.vectors_to_array([[1, 3], [2, 4]], identity)
    2×2 Matrix{Int64}:
    1  2
    3  4
"""
function vectors_to_array(vecvec::Vector{<:AbstractArray}, unpackfn)
    firstvec = unpackfn(first(vecvec))
    vs = size(firstvec)
    T = eltype(firstvec)

    a = Array{T}(undef, (vs..., length(vecvec)))
    vcolons = ntuple(x->Colon(), length(vs))

    # function barrier optimisation 
    function _fill(vecvec, vcolons::NTuple)
        for (i, vec) in enumerate(vecvec)
            a[vcolons..., i] .= unpackfn(vec)
        end
    end

    _fill(vecvec, vcolons)

    return a
end

"""
    array_to_vectors(array::AbstractArray, packfn) -> vecvec::Vector{<:Array}

Create vector-of-arrays length = size of last dimension of array 

# Examples
    julia> PALEOmodel.OutputWriters.array_to_vectors([1 2; 3 4], identity) # 2x2 Matrix
    2-element Vector{Vector{Int64}}:
    [1, 3]
    [2, 4]

    julia> PALEOmodel.OutputWriters.array_to_vectors([1 2], identity) # 1x2 Matrix
    2-element Vector{Vector{Int64}}:
     [1]
     [2]

     julia> PALEOmodel.OutputWriters.array_to_vectors([1, 2], identity) # 2-element Vector 
     2-element Vector{Int64}:
      1
      2
"""
function array_to_vectors(array::AbstractArray, packfn)
   
    vs = size(array)[1:end-1] 
    vcolons = ntuple(x->Colon(), length(vs))

    vecvec = [packfn(array[vcolons..., i]) for i in 1:last(size(array))]

    return vecvec
end



function subdomain_to_netcdf!(ds, name::AbstractString, subdom::PB.Grids.BoundarySubdomain)
    NCDatasets.defDim(ds, "subdomain_"*name, length(subdom.indices))

    v = NCDatasets.defVar(ds, "subdomain_"*name, subdom.indices .- 1 , ("subdomain_"*name,)) # convert to zero based
    v.attrib["subdomain_type"] = "BoundarySubdomain"
end

function subdomain_to_netcdf!(ds, name::AbstractString, subdom::PB.Grids.InteriorSubdomain)
    NCDatasets.defDim(ds, "subdomain_"*name, length(subdom.indices))

    # NB: issue in NCDatasets v0.13 (probably) - v0.14.1 causes failure, fixed in v0.14.2 
    # https://github.com/Alexander-Barth/NCDatasets.jl/issues/246
    # "v0.14 cannot create variable from an Int64 array with missing values"

    v = NCDatasets.defVar(ds, "subdomain_"*name, subdom.indices .- 1, ("subdomain_"*name,)) # convert to zero based
    v.attrib["subdomain_type"] = "InteriorSubdomain"
end

function netcdf_to_subdomains(dsvars)
    subdomains = Dict{String, PB.AbstractSubdomain}()

    for (vname, v) in dsvars
        if haskey(v.attrib, "subdomain_type")
            subdomain_type = v.attrib["subdomain_type"]
            if subdomain_type == "BoundarySubdomain"
                subdom = PB.Grids.BoundarySubdomain(Array(v))
            elseif subdomain_type == "InteriorSubdomain"
                subdom = PB.Grids.InteriorSubdomain(Array(v))
            else
                error("invalid subdomain_type = $subdomain_type")
            end
            subdom_name = vname[11:end] # strip "subdomain_"
            subdomains[subdom_name] = subdom
        end
    end

    return subdomains
end

function grid_to_netcdf!(ds, grid::Nothing)
    ds.attrib["PALEO_GridType"] = "Nothing"

    return ((), identity)
end


function grid_to_netcdf!(ds, grid::PB.Grids.UnstructuredVectorGrid)

    ds.attrib["PALEO_GridType"] = "UnstructuredVectorGrid"

    NCDatasets.defDim(ds, "cells", grid.ncells)

    # named cells
    cellnames = [String(k) for (k, v) in grid.cellnames]
    cellnames_indices = [v for (k, v) in grid.cellnames]
    ds.attrib["PALEO_cellnames"] = cellnames
    ds.attrib["PALEO_cellnames_indices"] = cellnames_indices .- 1 # zero offset for netcdf
    
    # subdomains
    for (name, subdom) in grid.subdomains
        subdomain_to_netcdf!(ds, name, subdom)
    end

    return (("cells", ), identity)
end

function grid_to_netcdf!(ds, grid::PB.Grids.UnstructuredColumnGrid)

    ds.attrib["PALEO_GridType"] = "UnstructuredColumnGrid"

    NCDatasets.defDim(ds, "cells", grid.ncells)
    NCDatasets.defDim(ds, "columns", length(grid.Icolumns))
   
    # similar to netCDF CF contiguous ragged array representation
    v = NCDatasets.defVar(ds, "cells_in_column", [length(ic) for ic in grid.Icolumns], ("columns",)) 
    # v.attrib["sample_dimension"] = "cells"  # similar to, but not the same as, netCDF CF contiguous ragged array
    v.attrib["comment"] = "number of cells in each column"
    Icolumns = reduce(vcat, grid.Icolumns)
    v = NCDatasets.defVar(ds, "Icolumns", Icolumns .- 1, ("cells",)) # NB: zero-based
    v.attrib["comment"] = "zero-based indices of cells from top to bottom ordered by columns"

    # optional z_coords
    # we only store name, assuming the coord data will be a variable
    z_coord_names = String[zc.name for zc in grid.z_coords]
    ds.attrib["PALEO_z_coords"] = z_coord_names

    # optional column labels
    if !isempty(grid.columnnames)    
        v = NCDatasets.defVar(ds, "columnnames", String.(grid.columnnames), ("columns",))
    end

    # subdomains
    for (name, subdom) in grid.subdomains
        subdomain_to_netcdf!(ds, name, subdom)
    end

    return (("cells", ), identity)
end

function grid_to_netcdf!(ds, grid::PB.Grids.CartesianArrayGrid{N}) where {N}

    ds.attrib["PALEO_GridType"] = "CartesianArrayGrid"

    _cartesiandimscoords_to_netcdf(ds, grid)

    # subdomains
    for (name, subdom) in grid.subdomains
        subdomain_to_netcdf!(ds, name, subdom)
    end

    return (Tuple(grid.dimnames), identity)
end

function grid_to_netcdf!(ds, grid::PB.Grids.CartesianLinearGrid{N}) where {N}

    ds.attrib["PALEO_GridType"] = "CartesianLinearGrid"

    ds.attrib["PALEO_columns"] = grid.ncolumns

    _cartesiandimscoords_to_netcdf(ds, grid)

    nc_linear_index = NCDatasets.defVar(ds, "linear_index", grid.linear_index .- 1, grid.dimnames) # netcdf zero indexed
    nc_linear_index.attrib["coordinates"] = join(grid.dimnames, " ")
 
    # # CF conventions 'lossless compression by gathering'
    # poorly supported ? (doesn't work with xarray or iris)
    # nc_cells = NCDatasets.defVar(ds, "cells", Int, ("cells",))
    # # rightmost entry in the compress list varies most rapidly
    # # (C like array convention is used by netCDF CF)
    # # we reverse dimnames so leftmost entry in dimnames varies most rapidly
    # # (so we have a Julia/Fortran/Matlab like array convention for compress)
    # nc_cells.attrib["compress"] = join(reverse(grid.dimnames), " ") 
    # cells = Int[]
    # for ci in grid.cartesian_index
    #     cit = Tuple(ci)
    #     cell = cit[1] - 1
    #     cell += (cit[2]-1)*grid.dims[1]
    #     if N == 3
    #         cell += (cit[3])*grid.dims[1]*grid.dims[2]
    #     end
    #     push!(cells, cell)
    # end
    # nc_cells[:] .= cells

    # subdomains
    for (name, subdom) in grid.subdomains
        subdomain_to_netcdf!(ds, name, subdom)
    end

    spatial_unpackfn = d -> PB.Grids.internal_to_cartesian(grid, d) # unpack linear representation into cartesian grid

    return (Tuple(grid.dimnames), spatial_unpackfn)
end

function _cartesiandimscoords_to_netcdf(
    ds::NCDatasets.Dataset,
    grid::Union{PB.Grids.CartesianLinearGrid{N}, PB.Grids.CartesianArrayGrid{N}}
) where {N}
  
    # dimensions
    NCDatasets.defDim(ds, "cells", grid.ncells)
   
    ds.attrib["PALEO_dimnames"] = grid.dimnames
    for (dimname, dim) in zip(grid.dimnames, grid.dims)
        NCDatasets.defDim(ds, dimname, dim)
    end
    # coordinates
    ds.attrib["PALEO_zidxsurface"] = grid.zidxsurface
    ds.attrib["PALEO_display_mult"] = grid.display_mult

    have_coords = (length(grid.coords) == length(grid.dims))
    have_edges = (length(grid.coords_edges) == length(grid.dims))
    if have_edges
        NCDatasets.defDim(ds, "bnds", 2)
    end
    if have_coords
        for (i, dimname) in enumerate(grid.dimnames)
            cv = NCDatasets.defVar(ds, dimname, grid.coords[i], (dimname,))
            if i == grid.londim
                cv.attrib["axis"] = "X"
                cv.attrib["units"] = "degrees_east"
                cv.attrib["long_name"] = "longitude"
            elseif i == grid.latdim
                cv.attrib["axis"] = "Y"
                cv.attrib["units"] = "degrees_north"
                cv.attrib["long_name"] = "latitude"
            elseif i == grid.zdim
                cv.attrib["axis"] = "Z"
                cv.attrib["units"] = "meters"
                cv.attrib["positive"] = grid.display_mult[i] > 0 ? "up" : "down"
            end
            if have_edges
                bndsname = dimname*"_bnds"
                cv.attrib["bounds"] = bndsname
                coord_edges = grid.coords_edges[i]
                bv = NCDatasets.defVar(ds, bndsname, eltype(coord_edges), ("bnds", dimname,))
                bv[1, :] .= coord_edges[1:end-1]
                bv[2, :] .= coord_edges[2:end]
            end
        end
    end

    return nothing
    
end
    


function netcdf_to_grid(ds::NCDatasets.Dataset, dsvars::Dict)
    gridtypes = Dict(
        "Nothing" => Nothing,
        "UnstructuredVectorGrid" => PB.Grids.UnstructuredVectorGrid,
        "UnstructuredColumnGrid" => PB.Grids.UnstructuredColumnGrid,
        "CartesianArrayGrid" => PB.Grids.CartesianArrayGrid,
        "CartesianLinearGrid" => PB.Grids.CartesianLinearGrid,
    )

    gridtypestring = ds.attrib["PALEO_GridType"]
    if haskey(gridtypes, gridtypestring)
        return netcdf_to_grid(gridtypes[gridtypestring], ds, dsvars)
    else
        error("invalid PALEO_GridType $gridtypestring")
    end
end

netcdf_to_grid(::Type{Nothing}, ds::NCDatasets.Dataset, dsvars::Dict) = (nothing, identity)

function netcdf_to_grid(::Type{PB.Grids.UnstructuredVectorGrid}, ds::NCDatasets.Dataset, dsvars::Dict)
    ncells = ds.dim["cells"]
    subdomains = netcdf_to_subdomains(dsvars)

    vec_cellnames = Symbol.(ncattrib_as_vector(ds, "PALEO_cellnames"))
    vec_cellnames_indices = ncattrib_as_vector(ds, "PALEO_cellnames_indices") .+ 1 # netcdf is zero offset
    cellnames = Dict{Symbol, Int}(k=>v for (k, v) in zip(vec_cellnames, vec_cellnames_indices))
    
    return (PB.Grids.UnstructuredVectorGrid(ncells, cellnames, subdomains), identity)
end

function netcdf_to_grid(::Type{PB.Grids.UnstructuredColumnGrid}, ds::NCDatasets.Dataset, dsvars::Dict)
    ncells = ds.dim["cells"]
    subdomains = netcdf_to_subdomains(dsvars)  

    # convert contiguous ragged array representation
    # back to vector-of-vectors 
    cells_in_column = Array(dsvars["cells_in_column"]) # number of cells in each column
    Icolumns_indices = Array(dsvars["Icolumns"]) .+ 1  # netcdf is zero based
    Icolumns = Vector{Vector{Int}}()
    colstart = 1
    for cells_this_column in cells_in_column
        push!(Icolumns, Icolumns_indices[colstart:(colstart+cells_this_column-1)])
        colstart += cells_this_column
    end

    # optional z_coords
    z_coords = PB.FixedCoord[]
    for z_coord_name in ncattrib_as_vector(ds, "PALEO_z_coords")
        var = dsvars[z_coord_name]
        attributes = netcdf_to_attributes(var)
        !("records" in NCDatasets.dimnames(var)) || error("z_coord variable $z_coord_name is not constant! (has a records dimension)")
        push!(z_coords, PB.FixedCoord(z_coord_name, Array(var), attributes))
    end
  
    # optional column labels
    if haskey(dsvars, "columnnames")
        columnnames = Symbol.(Array(dsvars["columnnames"]))
    else
        columnnames = Symbol[]
    end
    
    return (PB.Grids.UnstructuredColumnGrid(ncells, Icolumns, z_coords, columnnames, subdomains), identity)
end

function netcdf_to_grid(::Type{PB.Grids.CartesianArrayGrid}, ds::NCDatasets.Dataset, dsvars::Dict)
    
    subdomains = netcdf_to_subdomains(dsvars)  

    ncells, dimnames, dims, zidxsurface, display_mult, coords, coords_edges, londim, latdim, zdim =
        _netcdf_to_cartesiandimscoords(PB.Grids.CartesianArrayGrid, ds, dsvars)

    grid = PB.Grids.CartesianArrayGrid{length(dims)}(
        ncells,
        dimnames, dims,
        coords, coords_edges,
        londim, latdim, zdim,
        zidxsurface, display_mult,
        subdomains,
    )
    
    return (grid, identity)
end

function netcdf_to_grid(::Type{PB.Grids.CartesianLinearGrid}, ds::NCDatasets.Dataset, dsvars::Dict)
    
    subdomains = netcdf_to_subdomains(dsvars)  

    ncells, dimnames, dims, zidxsurface, display_mult, coords, coords_edges, londim, latdim, zdim =
        _netcdf_to_cartesiandimscoords(PB.Grids.CartesianLinearGrid, ds, dsvars)
    ncolumns = ds.attrib["PALEO_columns"]

    # convert back to linear vectors
    linear_index = Array(dsvars["linear_index"]) .+ 1 # netcdf zero based
    # reconstruct cartesian index 
    cartesian_index = Vector{CartesianIndex{length(dims)}}()
    lin_cart_index = Int[]
    for ci in CartesianIndices(linear_index)
        i = linear_index[ci]
        if !ismissing(i)
            push!(lin_cart_index, i)
            push!(cartesian_index, ci)
        end
    end
    cartesian_index = [cartesian_index[i] for i in sortperm(lin_cart_index)]
    l = length(cartesian_index)
    l == ncells || error("cartesian <-> linear index invalid, length(cartesian_index) $l != ncells $ncells")

    grid = PB.Grids.CartesianLinearGrid{length(dims)}(
        ncells,
        ncolumns,    
        dimnames, dims,
        coords, coords_edges,
        londim, latdim, zdim,
        zidxsurface, display_mult,
        subdomains,
        linear_index,
        cartesian_index,
    )
    
    spatial_packfn = d -> PB.Grids.cartesian_to_internal(grid, d)

    return (grid, spatial_packfn)
end

function _netcdf_to_cartesiandimscoords(
    ::Type{GT}, 
    ds::NCDatasets.Dataset,
    dsvars::Dict,
) where {GT <: Union{PB.Grids.CartesianArrayGrid, PB.Grids.CartesianLinearGrid}}

    ncells = ds.dim["cells"]
    
    # dimensions and coordinates
    dimnames = ncattrib_as_vector(ds, "PALEO_dimnames")
    dims = Int[]
    zidxsurface = ds.attrib["PALEO_zidxsurface"]
    display_mult = ncattrib_as_vector(ds, "PALEO_display_mult")
   
    coords = Vector{Vector{Float64}}()
    coords_edges = Vector{Vector{Float64}}()
    londim, latdim, zdim = 0, 0, 0

    for (i, dimname) in enumerate(dimnames)
        push!(dims, ds.dim[dimname])
        if haskey(dsvars, dimname)
            dimvar = dsvars[dimname]
            push!(coords, Array(dimvar))
            axis = get(dimvar.attrib, "axis", nothing)
            if axis == "X"
                global londim = i
            elseif axis == "Y"
                global latdim = i
            elseif axis == "Z"
                global zdim = i
            end
            bndsname = dimname*"_bnds"
            if haskey(dsvars, bndsname)
                push!(coords_edges, vcat(ds[bndsname][1, :], ds[bndsname][2, end]))
            end
        end
    end
    isempty(coords) || (length(coords) == length(dimnames)) || error("spatial coordinates present but not on all dimensions")
    isempty(coords_edges) || (length(coords_edges) == length(dimnames)) || error("spatial coordinates edges present but not on all dimensions")

    return ncells, dimnames, dims, zidxsurface, display_mult, coords, coords_edges, londim, latdim, zdim
end

function name_to_netcdf(vname, attributes)

    vnamenetcdf = replace(vname, "/"=>"%")
    if vnamenetcdf != vname
        @debug "  replaced / with % in variable name $vname -> $vnamenetcdf" 
    end

    return vnamenetcdf
end

function netcdf_to_name(vnamenetcdf, attributes)
    vname = get(attributes, :var_name, vnamenetcdf)
    if vname != vnamenetcdf
        @debug "  replaced % with / in variable name $vnamenetcdf -> $vname" 
    end

    return vname
end

function attributes_to_netcdf!(v, attributes)

    for (aname, aval) in attributes
        # TODO serialize/deserialize attributes with type conversion
        
        if aname == :_FillValue
            # shouldn't happen as this will never be set by PALEO, and should be filtered out when netcdf file is read
            @warn "attributes_to_netcdf! netcdf variable $v ignoring netcdf reserved attribute $aname = $aval"
            continue
        elseif aname == :data_dims
            aval = String[v for v in aval] # Tuple to vector        
        else
            if (typeof(aval) in (Float64, Int64, String, Vector{Float64}, Vector{Int64}, Vector{String})) #  Bool))
                # supported netCDF type, no conversion
            else
                # anything else - convert to string
                aval = string(aval)
            end
        end

        v.attrib[String(aname)] = aval # string(aval)
    end

    return nothing
end

function netcdf_to_attributes(v)

    # explict type conversion for known attribute names
    known_attrib_to_typed = Dict(
        :space => v->parse(PB.AbstractSpace, last(split(v, "."))), # "PALEOboxes.CellSpace" fails, "CellSpace" works
        :field_data => v->parse(PB.AbstractData, v),
        :vfunction => v->parse(PB.VariableFunction, v),
        :vphase => v->parse(PB.VariablePhase, v),
        :datatype => v->isdefined(Base, Symbol(v)) ? getfield(Base, Symbol(v)) : v,  # look for a type eg Float64, fallback to String if not found
    )
    # convert string value for other attributes (currently just bools)
    attrib_val_to_typed = Dict(
        "false" => false,
        "true" => true,
    )

    attributes = Dict{Symbol, Any}()

    for (aname, avalnc) in v.attrib
        anamesym = Symbol(aname)
        # try known attribute then generic, then guess boolean conversions, then just leave as string
        if anamesym == :_FillValue
            # ignore reserved netcdf attributes
            continue
        elseif haskey(known_attrib_to_typed, anamesym)
            aval = known_attrib_to_typed[anamesym](avalnc)
        elseif PB.is_standard_attribute(anamesym) && PB.standard_attribute_type(anamesym) <: AbstractVector
            aval = isa(avalnc, Vector) ? avalnc : [avalnc] # stored as a vector but returned as a scalar if length 1
        elseif PB.is_standard_attribute(anamesym) && PB.standard_attribute_type(anamesym) <: Tuple
            aval = isa(avalnc, Vector) ? Tuple(avalnc) : (avalnc, ) # stored as a vector but returned as a scalar if length 1
        else
            # guess at how to convert values
            aval = get(attrib_val_to_typed, avalnc, avalnc)
        end
        attributes[anamesym] = aval
    end

    return attributes
end

# NCDatasets will return a scalar even if the attribute was written as a vector with 1 element
function ncattrib_as_vector(d, name) 
    x = d.attrib[name]
    if !isa(x, Vector)
        x = [x]
    end
    return x
end

function _check_filename_ext(filename, requiredext)
    froot, fext = splitext(filename)
    if isempty(fext)
        fext = requiredext
    elseif fext != requiredext
        error("filename '$filename' must have extension $requiredext")
    end
    filename = froot*fext

    return filename
end


end # module
